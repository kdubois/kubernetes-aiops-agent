# Kubernetes Agent Application Properties
url=http://localhost
quarkus.http.port=8080
quarkus.application.name=kubernetes-agent
agent.version=0.0.2
quarkus.container-image.registry=quay.io
quarkus.container-image.group=kevindubois
quarkus.container-image.name=kubernetes-agent
quarkus.container-image.tag=latest

# Kubernetes Config - Enable secrets
%prod.quarkus.kubernetes-config.enabled=true
%prod.quarkus.kubernetes-config.secrets.enabled=true
%prod.quarkus.kubernetes-config.secrets=kubernetes-agent
%prod.quarkus.kubernetes.namespace=openshift-gitops

quarkus.podman.platform=linux/amd64


# LangChain4j Configuration - Profile-based model selection
# Use -Dquarkus.profile=openai or -Dquarkus.profile=gemini to switch models
# Default profile is gemini
%prod.quarkus.profile=prod,gemini
%dev.quarkus.profile=dev,openai

quarkus.langchain4j.openai.chat-model.temperature=0.3
quarkus.langchain4j.openai.chat-model.max-tokens=1024
quarkus.langchain4j.openai.chat-model.top-p=0.95

# Base API key configuration (required for extension initialization)
# These are overridden by profile-specific settings
quarkus.langchain4j.ai.gemini.api-key=${GOOGLE_API_KEY:not-set}
quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY:not-set}

# Test profile
%test.quarkus.profile=test,openai
%test.quarkus.langchain4j.chat-model.provider=openai
%test.quarkus.langchain4j.openai.base-url=${OPENAI_BASE_URL:https://api.openai.com/v1}
%test.quarkus.langchain4j.openai.chat-model.model-name=${OPENAI_MODEL:gpt-4o}
%test.quarkus.langchain4j.openai.timeout=PT120S
%test.quarkus.langchain4j.openai.log-requests=false
%test.quarkus.langchain4j.openai.log-responses=true

# Gemini Profile Configuration (default)
%gemini.quarkus.langchain4j.chat-model.provider=ai-gemini
%gemini.quarkus.langchain4j.ai.gemini.chat-model.model-id=${GEMINI_MODEL:gemini-2.5-flash}
%gemini.quarkus.langchain4j.ai.gemini.api-key=${GOOGLE_API_KEY}
%gemini.quarkus.langchain4j.ai.gemini.timeout=PT60S
%gemini.quarkus.langchain4j.ai.gemini.log-requests=false
%gemini.quarkus.langchain4j.ai.gemini.log-responses=true

# OpenAI Profile Configuration
%openai.quarkus.langchain4j.chat-model.provider=openai
%openai.quarkus.langchain4j.openai.api-key=${OPENAI_API_KEY}
%openai.quarkus.langchain4j.openai.base-url=${OPENAI_BASE_URL:https://api.openai.com/v1}
%openai.quarkus.langchain4j.openai.chat-model.model-name=${OPENAI_MODEL:gpt-4o}
%openai.quarkus.langchain4j.openai.timeout=PT60S
%openai.quarkus.langchain4j.openai.log-requests=false
%openai.quarkus.langchain4j.openai.log-responses=true

# Logging
quarkus.log.level=INFO
quarkus.log.category."dev.langchain4j".level=DEBUG
quarkus.log.category."dev.kevindubois.rollout.agent".level=DEBUG
%dev.quarkus.log.category."dev.langchain4j.agentic".level=DEBUG
%dev.quarkus.log.category."dev.langchain4j.agentic.supervisor".level=DEBUG

# Enable CORS
quarkus.http.cors.enabled=true
quarkus.http.cors.origins=*
quarkus.http.cors.methods=GET,POST,PUT,DELETE,OPTIONS
quarkus.http.cors.headers=accept,authorization,content-type,x-requested-with

# GitHub REST Client Configuration
quarkus.rest-client.github-api.url=https://api.github.com
quarkus.rest-client.github-api.scope=jakarta.inject.Singleton

# Console mode configuration
# Use -Drun.mode=console to run in console mode
